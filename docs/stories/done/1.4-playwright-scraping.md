# Story 1.4: Playwright-based Article Scraping for JavaScript-Rendered Sites

**Story ID:** 1.4
**Epic ID:** Epic 1 â€“ RSS Ingestion & NLP Enrichment
**Status:** Active

## Objective

Enable full article text extraction from JavaScript-rendered news sites (e.g., AD.nl) that cannot be scraped with simple HTTP requests.

## Background/Context

- **Source:** AD.nl (Algemeen Dagblad) was added as RSS source but articles use client-side JavaScript rendering
- **Problem:** Standard httpx/trafilatura fetch returns only ~8KB HTML shell without article content
- **Current fallback:** RSS summary text (~100-200 chars) is used, limiting event clustering quality
- **Solution:** Add Playwright as optional fetch strategy for sources requiring JS rendering
- **Reference:** `backend/app/ingestion/` module, `SourceProfile` dataclass in `profiles.py`

### Evidence of Problem

```
=== NOS (server-rendered) ===
HTML size: ~139 KB (full content)

=== AD (JavaScript-rendered) ===
HTML size: ~8 KB (empty shell, content loaded by JS)
```

## Acceptance Criteria (AC)

- [ ] Given an article URL from AD.nl when fetched with Playwright strategy, then full article text is extracted (>500 chars typical).
- [ ] Given a SourceProfile with `fetch_strategy: "playwright"` when `fetch_article_html()` is called, then Playwright browser is used instead of httpx.
- [ ] Given a Playwright fetch failure when timeout/error occurs, then system falls back to RSS summary gracefully with appropriate logging.
- [ ] Given the existing NOS/NU.nl sources when articles are fetched, then they continue using the fast httpx strategy (no regression).
- [ ] Given Playwright is installed when `make setup` runs, then browser binaries are available without manual intervention.

## Subtask Checklist

### Dependencies & Setup
- [ ] Add `playwright` and `playwright-stealth` to `requirements.txt`
- [ ] Update `Makefile` to include `playwright install chromium` in setup target
- [ ] Document Playwright setup requirements in README.md

### Core Implementation
- [ ] Create `backend/app/ingestion/playwright_fetch.py` with async Playwright article fetcher
- [ ] Implement browser pool/context reuse for performance (avoid launching browser per article)
- [ ] Add `fetch_strategy: Literal["simple", "playwright"]` to `SourceProfile` dataclass
- [ ] Update `fetch_article_html()` in `fetcher.py` to route to Playwright when profile specifies it
- [ ] Add timeout and error handling with fallback to RSS summary
- [ ] Add structured logging for Playwright fetch operations

### Configuration
- [ ] Create/update `data/source_profiles/ad_rss.yaml` with `fetch_strategy: playwright`

### Testing
- [ ] Write unit tests mocking Playwright browser behavior
- [ ] Write integration test fetching real AD.nl article with Playwright
- [ ] Verify AD.nl articles now have full text in database after ingestion

## Testing Requirements

- **Unit tests:** Mock Playwright browser, verify routing logic based on fetch_strategy
- **Integration tests:** Fetch real AD.nl article URL, verify content length >500 chars
- **Regression tests:** Verify NOS/NU.nl still use httpx strategy and work correctly
- **Performance:** Measure fetch time per article with Playwright (~500ms-2s acceptable)
- **Definition of Done:** All ACs satisfied, tests passing, AD.nl articles have full text

## Technical Notes

- Use `playwright.async_api` for async compatibility with existing pipeline
- Consider browser context pooling to avoid cold-start latency per article
- Implement request interception to block images/CSS/fonts for faster page loads
- Use `playwright-stealth` to reduce bot detection risk
- Set reasonable timeouts: page load 30s, content extraction 10s
- Memory consideration: Chromium uses ~100-200MB RAM; ensure graceful shutdown

## Dependencies

- Story 1.2.1 (consent-aware fetch pipeline) - already complete
- Playwright Python package + Chromium browser binary

## Story Wrap Up (To be filled in AFTER agent execution)

- **Agent Model Used:** _pending_
- **Agent Credit or Cost:** _pending_
- **Date/Time Completed:** _pending_
- **Commit Hash:** _pending_
- **Change Log:** _pending_
