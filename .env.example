# === LLM credentials ===
# Mistral API key used for clustering insights; replace with real key before running the stack.
MISTRAL_API_KEY=your-mistral-api-key

# === Feed configuration ===
# Default NOS RSS feed for general news headlines.
RSS_NOS_URL=https://feeds.nos.nl/nosnieuwsalgemeen
# Default NU.nl RSS feed for binnenland nieuws.
RSS_NUNL_URL=https://www.nu.nl/rss/Algemeen

# === Scheduler cadence ===
# Interval (in minutes) for the ingest scheduler job.
SCHEDULER_INTERVAL_MINUTES=15

# === Persistence ===
# SQLAlchemy connection string; keep SQLite for local MVP.
DATABASE_URL=sqlite+aiosqlite:///./data/app.db

# === NLP and LLM settings ===
# Embedding model identifier used by sentence-transformers.
EMBEDDING_MODEL_NAME=paraphrase-multilingual-MiniLM-L12-v2
# Dimensionality of the embedding vectors produced by the selected model.
EMBEDDING_DIMENSION=384
# Directory for caching embeddings, TF-IDF models, etc.
MODEL_CACHE_DIR=./data/models
# Cached TF-IDF vectorizer path; regenerate automatically when missing.
TFIDF_CACHE_PATH=./data/models/tfidf_vectorizer.joblib
# Maximum number of terms retained by the TF-IDF vectorizer.
TFIDF_MAX_FEATURES=6000
# spaCy model used for Dutch preprocessing and NER.
SPACY_MODEL_NAME=nl_core_news_lg
# Active LLM provider slug (e.g. mistral, openai); adapter uses this value.
LLM_PROVIDER=mistral
# Maximum number of articles included when building an LLM prompt (tune for quality vs. cost).
LLM_PROMPT_ARTICLE_CAP=8
# Hard character limit for the generated prompt (guards against token explosions).
LLM_PROMPT_MAX_CHARACTERS=7000
# Default model name used when calling the LLM provider (Mistral by default).
LLM_MODEL_NAME=mistral-small-latest
# Temperature applied to insight generation calls (0 keeps responses deterministic).
LLM_TEMPERATURE=0.2
# Base URL for the configured LLM API; keep default for hosted Mistral.
LLM_API_BASE_URL=https://api.mistral.ai/v1
# Request timeout for LLM calls (seconds).
LLM_API_TIMEOUT_SECONDS=45
# Retry attempts and base delay for transient LLM errors.
LLM_API_MAX_RETRIES=3
LLM_API_RETRY_BACKOFF_SECONDS=2

# === Event detection / vector index ===
# Location of the persisted hnswlib index file.
VECTOR_INDEX_PATH=./data/vector_index.bin
# Metadata JSON saved alongside the index with parameter integrity information.
VECTOR_INDEX_METADATA_PATH=./data/vector_index.meta.json
# Initial capacity for the vector index (resize automatically when needed).
VECTOR_INDEX_MAX_ELEMENTS=20000
# hnswlib hyperparameters tuning accuracy/latency of the index.
VECTOR_INDEX_M=16
VECTOR_INDEX_EF_CONSTRUCTION=200
VECTOR_INDEX_EF_SEARCH=64
# Candidate retrieval defaults.
EVENT_CANDIDATE_TOP_K=10
EVENT_CANDIDATE_TIME_WINDOW_DAYS=7
# Event lifecycle configuration (archiving + maintenance).
EVENT_RETENTION_DAYS=14
EVENT_MAINTENANCE_INTERVAL_HOURS=24
EVENT_INDEX_REBUILD_ON_DRIFT=true
# Hybrid scoring weights and thresholds for event assignment.
EVENT_SCORE_WEIGHT_EMBEDDING=0.6
EVENT_SCORE_WEIGHT_TFIDF=0.3
EVENT_SCORE_WEIGHT_ENTITIES=0.1
EVENT_SCORE_THRESHOLD=0.82
EVENT_SCORE_TIME_DECAY_HALF_LIFE_HOURS=48
EVENT_SCORE_TIME_DECAY_FLOOR=0.35

# === Observability ===
# Global logging level for backend services.
LOG_LEVEL=INFO
