# Claude Code Guide - News Aggregator Project

This document provides Claude Code with essential context and guidelines for working on the 360¬∞ News Aggregator project.

## Rules
- Never commit without asking
- Frontend build warnings about `<img>` vs `<Image>` are expected and NOT errors - the build succeeds despite these warnings

## üìã Project Overview

A proof-of-concept news aggregation system that demonstrates pluralistic news consumption through:
- **Multi-source ingestion** (NOS, NU.nl RSS feeds)
- **Event detection** using hybrid ML approach (embeddings + TF-IDF + entities)
- **Bias analysis** with LLM-powered insights
- **Interactive web interface** for exploring news events and viewpoints

## üìö Essential Documentation

Always consult these canonical documents before starting any task:

| Document | Purpose | When to Reference |
| -------- | ------- | ---------------- |
| `docs/PRD.md` | Product scope, features, success metrics | Planning & feature decisions |
| `docs/architecture.md` | Tech stack, patterns, project structure | Implementation & design |
| `docs/context-events.md` | Event detection algorithm specification | ML/NLP work |
| `docs/stories/stories.md` | **Authoritative backlog** with ready-to-execute stories | Primary task source |

## üõ† Current Technical Setup

### Backend (Python 3.11)
- **Framework**: FastAPI with Uvicorn
- **Database**: Supabase PostgreSQL with SQLAlchemy ORM (asyncpg driver)
- **Dependencies**: venv + pip with `requirements.txt`
- **ML Stack**: PyTorch 2.2.2 + sentence-transformers 2.7.0 + hnswlib + spaCy (fully operational)
- **Testing**: pytest with coverage target ‚â•80%
- **Deployment**: Runs locally (heavy ML models), writes to cloud database

### Frontend (Next.js 14)
- **Framework**: Next.js App Router
- **Styling**: Tailwind CSS 3.4
- **Components**: React 18 with TypeScript
- **Data Access**: Direct Supabase queries via `@supabase/supabase-js`
- **Testing**: Playwright for E2E tests
- **Deployment**: Vercel (auto-deploys from GitHub)

### Deployment Architecture
- **Backend**: Runs locally (to avoid 512MB memory limits for ML models)
- **Database**: Supabase PostgreSQL (free tier, 500MB)
- **Frontend**: Vercel (free tier, auto-deploys from GitHub)
- **Data Flow**: Backend writes to Supabase ‚Üí Frontend reads from Supabase

### Development Tools
- **Build System**: Comprehensive Makefile with all dev targets
- **Linting**: ruff + black (Python), ESLint (JavaScript/TypeScript)
- **Environment**:
  - Backend: `.env` (DATABASE_URL, Mistral API key)
  - Frontend: `frontend/.env.local` (Supabase credentials)
- **Utility scripts**: `/scripts/test_rss_feeds.py` voor snelle feedchecks; voeg nieuwe helpers in dezelfde map toe

## ‚öôÔ∏è Quick Start Commands

```bash
# Setup everything
make setup              # Install both backend and frontend dependencies

# Development servers
make backend-dev        # Start backend on http://localhost:8000
make frontend-dev       # Start frontend on http://localhost:3000
make dev               # Start both servers

# Testing & Quality
make test              # Run backend tests
make lint              # Run linting for both backend and frontend
make validate          # Verify current setup is working

# Utilities
make help              # Show all available commands
make clean             # Clean up generated files
```

## üìù Implementation Guidelines

### 1. Story-Driven Development
- **Primary source**: All tasks must originate from `docs/stories/stories.md`
- **Follow order**: Execute stories in sequence unless user reprioritizes
- **Complete checklists**: Each story has detailed subtask checkboxes to follow
- **Update status**: Mark subtasks as completed and fill in "Story Wrap Up" sections

### 2. Architecture Compliance
- **Module structure**: Follow the repository pattern and modular monolith layout
- **Path conventions**:
  - Backend: `backend/app/` (services, routers, models, core)
  - Frontend: `frontend/app/` and `frontend/components/`
  - Data: `data/` (exports, models, cache)
- **Provider abstraction**: Keep LLM clients, feed readers, vector indices behind adapters for easy swapping

### 3. Code Quality Standards
- **Python**: PEP 8 + type hints, ruff + black formatting, pytest coverage ‚â•80%
- **TypeScript**: Strict mode + ESLint/Prettier, Playwright for E2E tests
- **Logging**: Structured logging with structlog and correlation IDs
- **Error handling**: Consistent error response format per architecture

### 4. Testing Requirements
- **Unit tests**: For all business logic and services
- **Integration tests**: For API endpoints and database operations
- **E2E tests**: For critical user workflows
- **Coverage**: Maintain ‚â•80% coverage target
- **CI**: Ensure GitHub Actions stay green

## üîß Development Workflow

### Starting a Story
1. **Read the story** completely in `docs/stories/stories.md`
2. **Review references** in PRD, architecture, and context documents
3. **Check prerequisites** (dependencies, previous stories)
4. **Plan implementation** following the story's subtask checklist

### During Implementation
1. **Create branches** for significant features
2. **Follow TDD** where appropriate (write tests first)
3. **Test frequently** using `make validate`, `make test`, `make lint`
4. **Update documentation** when stories require it
5. **Respect module boundaries** defined in architecture

### Completing a Story
1. **Verify acceptance criteria** are all satisfied
2. **Run full test suite** (`make test`, `make lint`)
3. **Update story status** (mark subtasks complete, fill wrap-up section)
4. **Report to user** with story ID, completed ACs, test outcomes
5. **Note manual steps** user must perform (API keys, etc.)

## üö® Important Notes

### Current Status
- **Backend**: Fully functional with Python 3.11 + venv, runs locally with Supabase PostgreSQL
- **Frontend**: Next.js 14 deployed on Vercel with light theme UI (Pluriformiteit)
- **Database**: Supabase PostgreSQL (cloud), direct queries from frontend via Supabase JS client
- **ML Features**: Fully operational - PyTorch embeddings, vector search (hnswlib), spaCy NER
- **LLM Classification**: Mistral-based semantic event type classification (replaced keyword matching)
- **Clustering Performance**: 32.0% clustering rate (2.16x improvement from 14.78% baseline)
- **LLM Insights**: Auto-generation working with Mistral API, narrative summaries, frames, coverage gaps
- **REST API**: Backend endpoints for admin/trigger functions
- **Event Detail**: Complete detail pages with timeline, clusters, contradictions, fallacies, frames
- **RSS Polling**: Automated every 15 minutes via APScheduler (backend)
- **Insight Backfill**: Scheduled job every 30 minutes catches up on missing LLM insights

### Scheduled Jobs (APScheduler)

| Job | Interval | Description |
| --- | -------- | ----------- |
| RSS Feed Polling | 15 min | Polls all RSS feeds for new articles |
| Insight Backfill | 15 min | Generates LLM insights for events missing them |
| International Enrichment | 2 hours | Adds international perspectives via Google News (Epic 9) |
| Event Maintenance | 24 hours | Refreshes centroids, archives stale events |

### LLM Prompts Updaten

De LLM prompts worden opgeslagen in de Supabase `llm_config` tabel. De lokale templates in `backend/app/llm/templates/` dienen als versiecontrole en referentie.

**BELANGRIJK: Houd database en lokale templates in sync!**
- Database = productie (wat de LLM daadwerkelijk gebruikt)
- Lokale templates = versiecontrole (voor git history en review)

**Beschikbare prompt keys:**
| Key | Bestand | Doel |
|-----|---------|------|
| `prompt_factual` | `factual_prompt.txt` | Fase 1: feitelijke analyse (summary, timeline, clusters) |
| `prompt_critical` | `critical_prompt.txt` | Fase 2: kritische analyse (frames, fallacies, authority) |
| `prompt_classification` | - | Artikel classificatie naar event type |

**Workflow bij prompt wijzigingen:**

1. **Wijzig BEIDE** - database √©n lokale template:
   ```bash
   # Update database
   PYTHONPATH=. python3.11 -c "
   import requests

   new_prompt = '''<NIEUWE PROMPT HIER>'''

   url = 'https://xfqvwplrgwubbgbumzwk.supabase.co/rest/v1/llm_config'
   headers = {
       'apikey': '<SUPABASE_ANON_KEY>',
       'Authorization': 'Bearer <SUPABASE_ANON_KEY>',
       'Content-Type': 'application/json',
       'Prefer': 'return=minimal'
   }
   resp = requests.patch(url + '?key=eq.prompt_factual', headers=headers, json={'value': new_prompt})
   print(f'Database: {resp.status_code}')  # 204 = success
   "
   ```

2. **Update lokale template** - bewerk `backend/app/llm/templates/<bestand>.txt` met dezelfde wijzigingen

3. **Test de wijziging:**
   ```bash
   curl -X POST "http://localhost:8000/admin/trigger/generate-insights/{event_id}"
   ```

4. **Commit lokale template** - zodat wijzigingen in git history staan

**Huidige prompt ophalen uit database:**
```bash
PYTHONPATH=. python3.11 -c "
import requests
url = 'https://xfqvwplrgwubbgbumzwk.supabase.co/rest/v1/llm_config'
headers = {'apikey': '<SUPABASE_ANON_KEY>'}
resp = requests.get(url + '?key=eq.prompt_factual&select=value', headers=headers)
print(resp.json()[0]['value'])
"
```

### Admin Endpoints

```bash
# Trigger RSS polling manually
curl -X POST "http://localhost:8000/admin/trigger/poll-feeds"

# Trigger insight backfill (default 10 events)
curl -X POST "http://localhost:8000/admin/trigger/backfill-insights"

# Trigger insight backfill with custom limit
curl -X POST "http://localhost:8000/admin/trigger/backfill-insights?limit=50"

# Generate insight for specific event
curl -X POST "http://localhost:8000/admin/trigger/generate-insights/{event_id}"

# Trigger event maintenance
curl -X POST "http://localhost:8000/admin/trigger/maintenance"

# International enrichment for specific event (Epic 9)
curl -X POST "http://localhost:8000/admin/trigger/enrich-international/{event_id}"

# Batch international enrichment (default 5 events)
curl -X POST "http://localhost:8000/admin/trigger/enrich-international-batch"

# Batch enrichment with custom limit
curl -X POST "http://localhost:8000/admin/trigger/enrich-international-batch?limit=10"

# Check scheduler status
curl "http://localhost:8000/admin/scheduler/status"
```

### What NOT to Do
- ‚ùå Don't install Poetry (project uses venv + pip)
- ‚ùå Don't upgrade Python beyond 3.11 (PyTorch compatibility)
- ‚ùå Don't create features outside the story backlog
- ‚ùå Don't skip testing requirements
- ‚ùå Don't commit secrets or API keys (especially Supabase credentials)
- ‚ùå Don't try to deploy backend to cloud (runs locally due to ML models)

### When to Ask for Help
- If story requirements conflict with current setup
- If you need credentials or external API access
- If tests are failing due to missing dependencies
- If architecture decisions need clarification

## üìÅ Key File Locations

```
‚îú‚îÄ‚îÄ docs/
‚îÇ   ‚îú‚îÄ‚îÄ PRD.md                    # Product requirements
‚îÇ   ‚îú‚îÄ‚îÄ architecture.md          # Technical blueprint
‚îÇ   ‚îú‚îÄ‚îÄ context-events.md         # Event detection spec
‚îÇ   ‚îî‚îÄ‚îÄ stories/stories.md        # **PRIMARY TASK SOURCE**
‚îú‚îÄ‚îÄ backend/
‚îÇ   ‚îú‚îÄ‚îÄ app/                     # Main application code
‚îÇ   ‚îî‚îÄ‚îÄ tests/                   # Test suites
‚îú‚îÄ‚îÄ frontend/                    # Next.js application
‚îú‚îÄ‚îÄ scripts/                     # CLI helpers (RSS probe, smoke tests)
‚îú‚îÄ‚îÄ data/                        # Exports, models, cache
‚îú‚îÄ‚îÄ requirements.txt             # Python dependencies
‚îú‚îÄ‚îÄ .env.example                 # Environment template
‚îú‚îÄ‚îÄ Makefile                     # Development commands
‚îî‚îÄ‚îÄ CLAUDE.md                    # **THIS FILE**
```

## üéØ Success Criteria

- Stories completed according to acceptance criteria
- Tests passing with ‚â•80% coverage
- Code follows architecture patterns and quality standards
- Documentation stays current with implemented features
- User can run `make setup` ‚Üí `make dev` ‚Üí functional application

---

**Remember**: This is a proof-of-concept demonstrating pluralistic news analysis. Focus on working functionality over optimization, but maintain good architecture for future scaling.